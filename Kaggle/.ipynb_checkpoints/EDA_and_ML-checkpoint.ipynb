{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b828c46f913d3767c01de7e2d6192d5706e4619",
    "colab_type": "text",
    "id": "BGi45RunhgSq"
   },
   "source": [
    "## Data Cleaning and Shape Examining \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ad7ddccf61efdb2e9e7dd131aa7ae38f6dc6543",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "a0Sqe1x7hjzu",
    "outputId": "da28f8a4-fb3c-4505-d9c5-34726bfb4246"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "1720d9873a1549cd29ce34e9c821ca3628dfd3fe",
    "colab": {},
    "colab_type": "code",
    "id": "nqvGk3kkhgSv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "training_data = pd.read_csv(\"input/train.csv.zip\", encoding=\"ISO-8859-1\")\n",
    "testing_data = pd.read_csv(\"input/test.csv.zip\", encoding=\"ISO-8859-1\")\n",
    "attribute_data = pd.read_csv('input/attributes.csv.zip')\n",
    "descriptions = pd.read_csv('input/product_descriptions.csv.zip')\n",
    "\n",
    "training_data = pd.merge(training_data, descriptions, \n",
    "                         on=\"product_uid\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f54e9a8f8cc18605e917d47aca6feebfb97b151",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "78PcQC__hgS4",
    "outputId": "862af9df-97c3-49be-ed7e-5d19ed08c58d"
   },
   "outputs": [],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f21f1d572542158e7f45134c0189724c448af73",
    "colab_type": "text",
    "id": "eXunump9hgTA"
   },
   "source": [
    "As in the dataset page has mentioned that it might contains some embedded html tags, let's plot and see how many in percentage, more prececily the fields 'product_description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66018a689e75b4413ae9f944f625378e42e6bb55",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "mD3zyodThgTD",
    "outputId": "e4611f88-2a09-4554-dcf3-f6995b02796a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "total_length = len(descriptions['product_description'] )\n",
    "has_tag = sum([1 for _ in descriptions['product_description'] if '<br' in _])\n",
    "no_tags = total_length - has_tag\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(x=[has_tag])\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "_ = plt.xlabel('number of phrase which has html tags in')\n",
    "\n",
    "plt.show()\n",
    "print('has html tags in ',has_tag)\n",
    "print('doesn\\'t have html tags in ', no_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84fbef6e79ac8b621c58e61c715e376eb803c9a9",
    "colab_type": "text",
    "id": "p8LoHiaRhgTJ"
   },
   "source": [
    "Now let's see what is the frequency of search query which include digits in it with respect to product_title which \n",
    "includes words. As you can see most of them includes digits in search bar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "955978a5e37338a3f79153ca7ef1163c2deddb4a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "fcw8aOLVhgTL",
    "outputId": "5bf61497-3243-4b3d-a9e0-e4d0313c92b5"
   },
   "outputs": [],
   "source": [
    "(training_data.search_term.str.count(\"\\\\w+\") + 1).hist(bins=30) #plot number of words in search therms\n",
    "(training_data.search_term.str.count(\"\\\\d+\") + 1).hist(bins=30) #plot number of digits in search terms\n",
    "# (training_data.product_title.str.count(\"\\\\d+\") + 1).hist(bins=30)#plot number of digits in title\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05b2c663b3c6598194a5a4c2453828afccf11b71",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "reW74Co1hgTR",
    "outputId": "5f8454a7-9975-4f09-c473-222de8f65f60"
   },
   "outputs": [],
   "source": [
    "(training_data.product_title.str.count(\"\\\\w+\") + 1).hist(bins=30)#plot number of words in title\n",
    "(training_data.search_term.str.count(\"\\\\w+\") + 1).hist(bins=30) #plot number of words in search query\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2fc626dc42a2fffd5dc04518fde03f1c92617fe0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "xRYiXtBbhgTZ",
    "outputId": "c4e90de1-b7f7-48f5-841f-9bf109eedcd1"
   },
   "outputs": [],
   "source": [
    "(training_data.product_title.str.count(\"\\\\d+\") + 1).hist(bins=30)#plot number of words in title\n",
    "(training_data.search_term.str.count(\"\\\\d+\") + 1).hist(bins=30) #plot number of words in search query\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53f729c8f311b40e736c9b1850d327ce44b28c24",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "qcpD17U5hgTh",
    "outputId": "3380f8b4-4d09-4da8-f18c-fdf3802ce872"
   },
   "outputs": [],
   "source": [
    "(training_data.product_description.str.count(\"\\\\d+\") + 1).hist(bins=30)\n",
    "(training_data.product_description.str.count(\"\\\\d+\\W+\\d+\") + 1).hist(bins=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6295bb7eca8efb42e364a95169bec7b576dcae5",
    "colab_type": "text",
    "id": "n-UOBiz0hgTt"
   },
   "source": [
    "let's plot at histogram following number of words in search query, and on the other hand relevancy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00266e9726a7fec706b072b6b86281cf00c27cb9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "Cegd1o0phgTv",
    "outputId": "4f66723a-9243-473b-f122-094814ea2b08"
   },
   "outputs": [],
   "source": [
    "(training_data.search_term.str.count(\"\\\\w+\") + 1).hist(bins=30)\n",
    "(training_data.relevance + 1).hist(bins=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78af8c77dea8fe2179735932ef295d96433ea8cf",
    "colab_type": "text",
    "id": "txZqaXn0hgT0"
   },
   "source": [
    "let's take a look how does the persistence of digits in the search query influence the relevancy score, from below plot it clearly that most of the search query must have between 2.0 and 3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2a1afe75959cc52edaf987727d87cdfcc988bc9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "vFzL6dsuhgT2",
    "outputId": "2b18aa72-e015-4836-9db5-76d9269a48de"
   },
   "outputs": [],
   "source": [
    "(training_data.search_term.str.count(\"\\\\d+\")).hist(bins=30)\n",
    "(training_data.relevance ).hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f4c658ac45a2da644cbf00badcc51ddb644a2d3",
    "colab_type": "text",
    "id": "1i4JNV2HhgT7"
   },
   "source": [
    "letâ€™s assume that there are zero response for null query search term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "702606c15a23a1f8bcaf369506d719a8f480ee8a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "5bekfrZZhgT9",
    "outputId": "27b742e6-2420-48ae-c9a0-b24ffd47b8dd"
   },
   "outputs": [],
   "source": [
    "training_data[training_data.search_term.str.count('\\\\w+') < 1]\n",
    "# training_data[training_data.search_term.str.contains('^\\d+') < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dbd3115e7aa81bb09fde3ea283b8f31dc885de56",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "zTyh6QnHhgUC",
    "outputId": "3e28d49d-442f-4bf3-d795-c26b97a77624"
   },
   "outputs": [],
   "source": [
    "# an interest case can be see below, unfortunattly we cannot get rid of this element since it will make a bad impact on model\n",
    "training_data[training_data.product_uid==100030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c86493591b2c80347dbb30794d17752dccb2999c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "qLK6NtZ7hgUJ",
    "outputId": "36df4ff3-d9c4-4a17-a38a-859fc59ea915"
   },
   "outputs": [],
   "source": [
    "training_data[training_data.product_description.str.contains('.* x .*')].head(4) # at first it looks like nothing unsual \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "65d0de70d59daf70f70bb539baa3de8572f988cb",
    "colab_type": "text",
    "id": "26BS8KLFhgUP"
   },
   "source": [
    "Unfortunately, it is kind ambiguous to figure out the meaning of digits in the search context like an example below, it can mean anything. we should take care of this when cleaning context. It looks that most of the case the meaning of X is denoted the unit of measure like fit/inch/or something by something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4a223cf4cf2162a5e723d69bd29287e958eb434",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "BgBG3ClMhgUQ",
    "outputId": "7e8fddb7-b57b-4ed1-c1d0-120cdf68b63d"
   },
   "outputs": [],
   "source": [
    "# training_data[training_data.search_term.str.contains(\"^\\\\d+ . \\\\d+$\")].head(4)\n",
    "training_data[(training_data.search_term.str.contains(\"^\\\\d+ . \\\\d+$\") )& (training_data.relevance > 2)].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97e55700afeec197d8d21bab071e5855b8b0f8c5",
    "colab_type": "text",
    "id": "CXJ6qmA8hgUb"
   },
   "source": [
    "In order to apply any standard method for analysis we have to standardize metric for text fields, which we define as follows\n",
    "\n",
    "- split into tokens by white space\n",
    "- remove punctuation from each token\n",
    "- remove remaining tokens that are not alphabetic\n",
    "- filter out stop words\n",
    "- filter out short tokens\n",
    "\n",
    "and lets also create new feature in the same time which will denote our hypothesis.\n",
    "\n",
    "\\begin{equation*}\n",
    "H_1 = \\{\\ \\frac{ card(search query)}{ card(product title)} = high\\ relevance\\ score\\} \\\\\n",
    "H_2 = \\{ length(search query)\\ influence\\ relevance\\ score \\} \\\\\n",
    "H_3 = \\{ card(common\\_words(search\\ query,product\\ title,product\\ description)) = influence\\ relevance\\ score \\} \\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9b1eff84cc084045a3dcfb7f4ebaf34380898781",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "wNvUTEEahgUe",
    "outputId": "c43af0b5-7981-44d6-a691-49b0e53bd8f1"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from nltk.metrics import edit_distance\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "def remove_html_tag(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    text = soup.get_text().replace('Click here to review our return policy for additional information regarding returns', '')\n",
    "    return text\n",
    "\n",
    "def str_stemmer(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def str_stemmer_title(s):\n",
    "    return \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "    whole_set = set(str1.split())\n",
    "    return sum(int(str2.find(word)>=0) for word in whole_set)\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e330e25193001be60477ed0aa0f066ca56058873",
    "colab_type": "text",
    "id": "Fd5F1ZGphgUk"
   },
   "source": [
    "Now let's apply those function to feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21ab783ea78856137325738bb6cb6ae492c64e65",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "8D-bAJDchgUn",
    "outputId": "8ee2b3bd-4c08-48c0-efd5-e7076655918b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_train = training_data.shape[0]\n",
    "############### cleaning html tags ##################\n",
    "has_tag_in = training_data.product_description.str.contains('<br')\n",
    "training_data.loc[has_tag_in, 'product_description'] = training_data.loc[has_tag_in, 'product_description'].map(lambda x:remove_html_tag(x))\n",
    "###############\n",
    "\n",
    "############## apply stemming #####################\n",
    "training_data['search_term'] = training_data['search_term'].map(lambda x:str_stemmer_title(x))\n",
    "training_data['product_title'] = training_data['product_title'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "training_data['product_description'] = training_data['product_description'].map(lambda x:str_stemmer(x))\n",
    "############## end stemming #####################\n",
    "\n",
    "############## building custome feature, let's build a few of them before compare which one is the best ###########\n",
    "training_data['len_of_query'] = training_data['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "training_data['shared_words'] = training_data[['search_term','product_description', 'product_title']].apply(lambda row:sum([str_common_word(*row[:-1]), str_common_word(*row[1:])]), axis=1)\n",
    "\n",
    "# training_data['frequency_digits_in_sq']=training_data.product_description.str.count(\"\\\\d+\")\n",
    "training_data['frequency_words_in_sq'] = training_data.product_description.str.count(\"\\\\w+\")\n",
    "training_data[\"distance\"] = training_data.loc[:, [\"search_term\",\"product_title\"]].apply(lambda x: edit_distance(*x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58a8fd421556f14aae735f4b179486d261dc2466",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "moBdZ8SchgUw",
    "outputId": "5cdbd166-8cd5-45f2-ad5d-85d8c8ec6ddb"
   },
   "outputs": [],
   "source": [
    "#let's take a look if there is not empty search query now\n",
    "empty_search_query = training_data[training_data.search_term.str.count('\\\\w+') < 1].values\n",
    "print('data frame of empty seach query along with products',empty_search_query)\n",
    "# training_data[training_data.product_uid==100030]\n",
    "is_anything_none = training_data.isnull().values.any()\n",
    "print('presence of Nan values',  is_anything_none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62a89ae2e2925f9870e489dadb1b9168218b0523",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "Z5kKyVZZhgU1",
    "outputId": "6f7182ae-d237-490b-c432-439cd47c2f2d"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c7f97a17836a705f1e8a098ece7c171188c80a9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "SecjsKcjhgU4",
    "outputId": "bc13f12b-2ad7-45f4-c1a8-ae51719dbde7"
   },
   "outputs": [],
   "source": [
    "training_data[training_data.search_term.str.match(\"\\\\d+ x \\\\d+\") > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b704b28adb5e5efaf2034860b8490093b201efd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "IHUgJIxx3s4s",
    "outputId": "783abc29-26dd-4b93-c9b5-104144114390"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bc6211c690e4d2395243cb54564eb9a8239242c",
    "colab": {},
    "colab_type": "code",
    "id": "jSKc4U6GqBME"
   },
   "outputs": [],
   "source": [
    "#lets create new feature which will denote \n",
    "training_data['test'] = training_data[['shared_words', 'frequency_words_in_sq']].apply(lambda row:row[1]+row[0],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd86d03f65c6298bc88b0c018db0d25f9af9a79e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "r7e4vBF-hgU8",
    "outputId": "da94c93e-b9a8-4941-a9d6-88ad8017ace3"
   },
   "outputs": [],
   "source": [
    "training_data[['product_title','len_of_query','shared_words','frequency_words_in_sq','relevance', 'test']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20e1969df30c2841a7e7336a29ef75ef1fbeafd9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "YgtTGgzbhgU9",
    "outputId": "30b03ad8-aef1-4ebb-f089-a32907033ee6"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# r = training_data[training_data.search_term.str.contains('^\\d+\\s+?\\w\\s+?\\d+$')]\n",
    "# (r.relevance ).hist(bins=30)\n",
    "# r.describe()\n",
    "training_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "925eb015e7d3fc199052121835b7ebc0fd9a5173",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "mOetNpVMhgVC",
    "outputId": "41db7474-b780-45f4-e690-58707741c47b"
   },
   "outputs": [],
   "source": [
    "df_all = training_data.drop(['search_term','product_description','product_title','test'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9616a548413580f2509ed7ccffd8214eef175b56",
    "colab": {},
    "colab_type": "code",
    "id": "fjECFoW68nDX"
   },
   "outputs": [],
   "source": [
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train.drop(['id','relevance'],axis=1).values\n",
    "X_test = df_test.drop(['id','relevance'],axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8343edb6fc3ae8ea6e951bd4595d1c158506159",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "oNO-b-Rq9QYx",
    "outputId": "616d8eab-b199-4a9c-f5e1-1225e22366d4"
   },
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa70eda3af4851a40304b34ec55c43715a601090",
    "colab": {},
    "colab_type": "code",
    "id": "t5AWitbK87zK"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=4, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7f2e70686dbdc26fac1709c502f5765a7a7af3a",
    "colab": {},
    "colab_type": "code",
    "id": "2L4kUtZ49C_l"
   },
   "source": [
    "Analysis of the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7f23f22d4838dc39f4e01f4ec8ae5f9fc75770a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iurii/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/Users/iurii/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train            id  product_uid  relevance\n",
      "0           2       100001       3.00\n",
      "1           3       100001       2.50\n",
      "2           9       100002       3.00\n",
      "3          16       100005       2.33\n",
      "4          17       100005       2.67\n",
      "5          18       100006       3.00\n",
      "6          20       100006       2.67\n",
      "7          21       100006       3.00\n",
      "8          23       100007       2.67\n",
      "9          27       100009       3.00\n",
      "10         34       100010       2.67\n",
      "11         35       100011       3.00\n",
      "12         37       100011       3.00\n",
      "13         38       100011       2.00\n",
      "14         48       100012       2.67\n",
      "15         51       100013       2.67\n",
      "16         65       100016       3.00\n",
      "17         69       100017       1.00\n",
      "18         75       100017       1.67\n",
      "19         81       100017       2.33\n",
      "20         85       100017       2.33\n",
      "21         88       100019       1.33\n",
      "22         90       100019       2.67\n",
      "23         92       100019       2.33\n",
      "24        101       100019       1.33\n",
      "25        105       100019       2.33\n",
      "26        106       100019       2.33\n",
      "27        113       100021       2.00\n",
      "28        114       100021       2.33\n",
      "29        117       100022       2.67\n",
      "...       ...          ...        ...\n",
      "74037  221398       206588       1.67\n",
      "74038  221400       206589       1.33\n",
      "74039  221401       206590       2.33\n",
      "74040  221404       206593       2.33\n",
      "74041  221405       206594       2.67\n",
      "74042  221407       206596       1.67\n",
      "74043  221408       206597       3.00\n",
      "74044  221409       206598       2.67\n",
      "74045  221411       206599       1.33\n",
      "74046  221412       206600       2.00\n",
      "74047  221413       206601       1.67\n",
      "74048  221415       206602       2.00\n",
      "74049  221416       206603       1.00\n",
      "74050  221419       206606       2.33\n",
      "74051  221420       206607       2.00\n",
      "74052  221422       206609       2.33\n",
      "74053  221423       206610       2.33\n",
      "74054  221426       206613       2.00\n",
      "74055  221427       206614       1.67\n",
      "74056  221432       206619       2.00\n",
      "74057  221434       206621       2.67\n",
      "74058  221443       206627       3.00\n",
      "74059  221449       206631       3.00\n",
      "74060  221450       206632       2.00\n",
      "74061  221455       206637       3.00\n",
      "74062  221457       206638       1.00\n",
      "74063  221458       206639       3.00\n",
      "74064  221463       206641       2.33\n",
      "74065  221471       206648       3.00\n",
      "74066  221473       206650       2.33\n",
      "\n",
      "[74067 rows x 3 columns]\n",
      "df_test             id  product_uid  relevance\n",
      "74067        1       100001        NaN\n",
      "74068        4       100001        NaN\n",
      "74069        5       100001        NaN\n",
      "74070        6       100001        NaN\n",
      "74071        7       100001        NaN\n",
      "74072        8       100001        NaN\n",
      "74073       10       100003        NaN\n",
      "74074       11       100003        NaN\n",
      "74075       12       100003        NaN\n",
      "74076       13       100004        NaN\n",
      "74077       14       100005        NaN\n",
      "74078       15       100005        NaN\n",
      "74079       19       100006        NaN\n",
      "74080       22       100006        NaN\n",
      "74081       24       100008        NaN\n",
      "74082       25       100009        NaN\n",
      "74083       26       100009        NaN\n",
      "74084       28       100010        NaN\n",
      "74085       29       100010        NaN\n",
      "74086       30       100010        NaN\n",
      "74087       31       100010        NaN\n",
      "74088       32       100010        NaN\n",
      "74089       33       100010        NaN\n",
      "74090       36       100011        NaN\n",
      "74091       39       100011        NaN\n",
      "74092       40       100011        NaN\n",
      "74093       41       100011        NaN\n",
      "74094       42       100011        NaN\n",
      "74095       43       100011        NaN\n",
      "74096       44       100011        NaN\n",
      "...        ...          ...        ...\n",
      "240730  240731       224399        NaN\n",
      "240731  240732       224400        NaN\n",
      "240732  240733       224401        NaN\n",
      "240733  240734       224402        NaN\n",
      "240734  240735       224403        NaN\n",
      "240735  240736       224404        NaN\n",
      "240736  240737       224405        NaN\n",
      "240737  240738       224406        NaN\n",
      "240738  240739       224407        NaN\n",
      "240739  240740       224408        NaN\n",
      "240740  240741       224409        NaN\n",
      "240741  240742       224410        NaN\n",
      "240742  240743       224411        NaN\n",
      "240743  240744       224412        NaN\n",
      "240744  240745       224413        NaN\n",
      "240745  240746       224414        NaN\n",
      "240746  240747       224415        NaN\n",
      "240747  240748       224416        NaN\n",
      "240748  240749       224417        NaN\n",
      "240749  240750       224418        NaN\n",
      "240750  240751       224419        NaN\n",
      "240751  240752       224420        NaN\n",
      "240752  240753       224421        NaN\n",
      "240753  240754       224422        NaN\n",
      "240754  240755       224423        NaN\n",
      "240755  240756       224424        NaN\n",
      "240756  240757       224425        NaN\n",
      "240757  240758       224426        NaN\n",
      "240758  240759       224427        NaN\n",
      "240759  240760       224428        NaN\n",
      "\n",
      "[166693 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iurii/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/iurii/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/iurii/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/iurii/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jan 28 13:54:11 2019\n",
    "\n",
    "@author: iurii\n",
    "\"\"\"\n",
    "\n",
    "from nltk.metrics import edit_distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"input/train.csv.zip\", encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv(\"input/test.csv.zip\", encoding=\"ISO-8859-1\")\n",
    "attribute_data = pd.read_csv('input/attributes.csv.zip')\n",
    "df_pro_desc = pd.read_csv('input/product_descriptions.csv.zip')\n",
    "\n",
    "\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "\n",
    "def str_stemmer(s):\n",
    "    return \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "    return sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "def str_stemmer_title(s):\n",
    "    return \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "\n",
    "############## apply stemming #####################\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer_title(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n",
    "############## end stemming #####################\n",
    "\n",
    "############## building custome feature, let's build a few of them before compare which one is the best ###########\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['shared_words'] = df_all[['search_term','product_description', 'product_title']].apply(lambda row:sum([str_common_word(*row[:-1]), str_common_word(*row[1:])]), axis=1).astype(np.int64)\n",
    "\n",
    "# training_data['frequency_digits_in_sq']=training_data.product_description.str.count(\"\\\\d+\")\n",
    "df_all['frequency_words_in_sq'] = df_all.product_description.str.count(\"\\\\w+\").astype(np.int64)\n",
    "df_all[\"distance_levistein\"] = df_all.loc[:, [\"search_term\",\"product_title\"]].apply(lambda x: edit_distance(*x), axis=1).astype(np.int64)\n",
    "\n",
    "df_all['length in product info'] = df_all[['product_title','product_description']].apply(lambda row:sum([len(*row[:-1]), len(*row[1:])]), axis=1).astype(np.int64)\n",
    "\n",
    "df_all = df_all.drop(['search_term','product_title','product_description'],axis=1)\n",
    "\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "print('df_train',df_train)\n",
    "df_test = df_all.iloc[num_train:]\n",
    "print('df_test',df_test)\n",
    "id_test = df_test['id']\n",
    "\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train.drop(['id','relevance'],axis=1).values\n",
    "X_test = df_test.drop(['id','relevance'],axis=1).values\n",
    "\n",
    "#### Feature to the same scale\n",
    "scX = StandardScaler()\n",
    "X_train = scX.fit_transform(X_train)\n",
    "X_test = scX.fit_transform(X_test)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=4, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=4, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)\n",
    "print(\"done, now you can submit the submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "77a6d49ae3a271a2554129165a8a71e982b4ad3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_description</th>\n",
       "      <th>len_of_query</th>\n",
       "      <th>shared_words</th>\n",
       "      <th>frequency_words_in_sq</th>\n",
       "      <th>distance_levistein</th>\n",
       "      <th>length in product info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, product_uid, product_title, search_term, relevance, product_description, len_of_query, shared_words, frequency_words_in_sq, distance_levistein, length in product info]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[training_data.search_term.str.count('\\\\w+')<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c61143c65f667a056eb4852715f05af06bf91d06"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0febb1253bafa58a82d82bbc4899016056e615ca"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EDA and ML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
